# ğŸ‡²ğŸ‡½ Mexico HR Job Scraper

A comprehensive web scraper for HR job listings from Mexican job sites.

## ğŸ“ Project Structure

```
Computrabajo-scrapper/
â”œâ”€â”€ ğŸ“ OCCMexicoScraper/          # OCC Mexico scraper module
â”‚   â”œâ”€â”€ ğŸ“„ scraper_occ.py         # OCC scraper logic
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py            # Package initialization
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt       # OCC scraper dependencies
â”‚   â””â”€â”€ ğŸ“„ README.md              # OCC scraper documentation
â”œâ”€â”€ ğŸ“ ComputrabajoScraper/       # Computrabajo scraper module
â”‚   â”œâ”€â”€ ğŸ“„ scraper.py             # Computrabajo scraper logic
â”‚   â”œâ”€â”€ ğŸ“„ main.py                # Computrabajo main script
â”‚   â”œâ”€â”€ ğŸ“„ models.py              # Database models
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py            # Package initialization
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt       # Computrabajo dependencies
â”‚   â””â”€â”€ ğŸ“„ README.md              # Computrabajo documentation
â”œâ”€â”€ ğŸ“ exports/                   # CSV exports and data files
â”œâ”€â”€ ğŸ“ scripts/                   # Utility and export scripts
â”œâ”€â”€ ğŸ“„ get_3000_occ_jobs_checkpoint.py  # Main checkpoint scraper
â”œâ”€â”€ ğŸ“„ get_3000_occ_jobs.py       # Original 3000 jobs scraper
â”œâ”€â”€ ğŸ“„ check_checkpoint.py        # Checkpoint status utility
â”œâ”€â”€ ğŸ“„ hr_mexico_summary.py       # HR jobs analysis script
â”œâ”€â”€ ğŸ“„ jobs.db                    # SQLite database
â”œâ”€â”€ ğŸ“„ *.csv                      # Job data exports
â””â”€â”€ ğŸ“„ requirements.txt           # Main project dependencies
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
playwright install
```

### 2. Run Scrapers

**Get 3000+ OCC Jobs (with checkpoint system):**
```bash
python get_3000_occ_jobs_checkpoint.py
```

**Check Progress:**
```bash
python check_checkpoint.py
```

**Get 3000+ OCC Jobs (original):**
```bash
python get_3000_occ_jobs.py
```

**Run Individual Scrapers:**
```bash
# OCC Scraper
python -m OCCMexicoScraper

# Computrabajo Scraper
python -m ComputrabajoScraper
```

### 3. Export Data

**Export Database to CSV:**
```bash
python scripts/export_db_to_csv.py
```

**Export OCC Jobs (No Duplicates):**
```bash
python scripts/export_occ_no_duplicates.py
```

## ğŸ“Š Data Sources

- **OCC Mexico**: HR job listings from occ.com.mx
- **Computrabajo**: HR job listings from mx.computrabajo.com

## ğŸ¯ Features

- âœ… **3000+ OCC Jobs**: Automatic scraping until target reached
- âœ… **Checkpoint System**: Resume from exactly where you left off
- âœ… **Real-time ETA**: Know exactly how long it will take
- âœ… **Real Link Extraction**: Actual job URLs from OCC
- âœ… **Real Description Extraction**: Full job descriptions from job pages
- âœ… **Duplicate Removal**: Smart deduplication by job links
- âœ… **Progress Saving**: Checkpoint saves after each page
- âœ… **Database Integration**: SQLite storage with source tracking
- âœ… **CSV Export**: Direct export to CSV files
- âœ… **Location Filtering**: Mexico-specific location detection
- âœ… **Concurrent Scraping**: Run both scrapers simultaneously

## ğŸ“ˆ Current Status

- **OCC Jobs**: Target 3000+ jobs with real links and descriptions
- **Computrabajo Jobs**: 2500+ jobs
- **Total Database**: 2700+ jobs

## ğŸ”§ Configuration

### OCC Scraper Settings
- **Keywords**: recursos-humanos, rrhh, rh, reclutamiento, seleccion, personal
- **Pages per keyword**: Auto-adjusting (starts at 50)
- **Wait time**: 5-8 seconds between requests
- **Location filter**: Mexico cities and states
- **Real Data**: Extracts actual job URLs and descriptions

### Computrabajo Scraper Settings
- **Keywords**: recursos humanos, rrhh, rh, reclutamiento, seleccion
- **Pages per keyword**: Configurable
- **Wait time**: 2-5 seconds between requests

## ğŸ“ File Organization

### `/OCCMexicoScraper/`
- Complete OCC scraper package
- Real link and description extraction
- Playwright-based browser automation

### `/ComputrabajoScraper/`
- Complete Computrabajo scraper package
- HTTP-based scraping
- Database integration

### `/exports/`
- CSV files with scraped data
- Progress checkpoints
- Final results

### `/scripts/`
- Export utilities
- Database checkers
- Analysis tools

## ğŸ¯ Next Steps

1. **Run Checkpoint Scraper**: `python get_3000_occ_jobs_checkpoint.py`
2. **Check Progress**: `python check_checkpoint.py`
3. **Analyze Data**: Use scripts in `/scripts/` folder
4. **Export Results**: CSV files in `/exports/` folder

## ğŸ“ Support

For issues or questions, check the `/exports/` folder for checkpoint files and progress data.

## ğŸ”„ Recent Updates

- âœ… **Organized Structure**: Separated OCC and Computrabajo scrapers into dedicated folders
- âœ… **Real Data Extraction**: OCC scraper now extracts actual job URLs and descriptions
- âœ… **Package Structure**: Both scrapers are now proper Python packages
- âœ… **Checkpoint System**: Resume scraping from exactly where you left off
- âœ… **Real-time ETA**: Know exactly how long the scraping will take
- âœ… **Page-by-Page Saving**: Never lose progress again
- âœ… **Clean Project**: Removed all test files and unused scripts
